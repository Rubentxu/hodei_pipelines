# GuÃ­a de Inicio RÃ¡pido: Hodei Pipelines con Docker

Esta guÃ­a completa te muestra cÃ³mo iniciar el orquestador y usar el CLI empresarial de Hodei (`hp`) para gestionar la ejecuciÃ³n distribuida de trabajos con Docker en tu mÃ¡quina local.

## Prerrequisitos

### Para InstalaciÃ³n EstÃ¡ndar
- **Java 17+** instalado
- **Docker** instalado y funcionando
- **Gradle** instalado (no usar gradlew segÃºn configuraciÃ³n del proyecto)

### Para Binario Nativo (Opcional pero Recomendado)
- **GraalVM 21+** instalado (para compilaciÃ³n nativa)
- Alternativa: Descargar binarios nativos pre-compilados desde releases

## Paso 1: Compilar el Proyecto

```bash
# Desde el directorio raÃ­z del proyecto
gradle clean build -x test
```

## Paso 2: Iniciar el Orquestador

```bash
# OpciÃ³n 1: Usando gradle
gradle :orchestrator:run

# OpciÃ³n 2: Usando el JAR generado
java -jar orchestrator/build/libs/orchestrator-all.jar

# El orquestador se iniciarÃ¡ en http://localhost:8080
```

El orquestador automÃ¡ticamente:
- **Inicializa usuarios por defecto** (admin/admin123, user/user123, moderator/mod123)
- **Descubre el entorno Docker** y lo registra como un pool de recursos
- **Crea plantillas de workers por defecto** para diferentes escenarios
- Expone la API REST en el puerto 8080
- Expone el servidor gRPC en el puerto 9090 (para comunicaciÃ³n con workers)

Salida esperada al inicio:
```
ğŸš€ Starting system bootstrap...
ğŸ” Initializing default users...
âœ… Created user: admin with roles: [ADMIN]
âœ… Created user: user with roles: [USER]  
âœ… Created user: moderator with roles: [MODERATOR]

ğŸ”‘ Credenciales de Usuario por Defecto (para testing del CLI):
==================================================
ğŸ‘‘ Admin:     admin / admin123
ğŸ‘¤ User:      user / user123
ğŸ›¡ï¸ Moderator: moderator / mod123
==================================================
ğŸ’¡ Usa estas credenciales con: hp login http://localhost:8080

ğŸ—ï¸ Entorno Docker registrado como pool de recursos
ğŸ“‹ Plantillas de worker por defecto creadas: 7 templates
==================================================
ğŸ”— Uso del CLI: hp login http://localhost:8080
ğŸ”— Health Check: curl http://localhost:8080/v1/health
```

## Paso 3: Configurar el CLI de Hodei (`hp`)

### OpciÃ³n A: Binario Nativo (Recomendado) âš¡

Para startup mÃ¡s rÃ¡pido y sin dependencia de JVM:

```bash
# Compilar binario nativo (requiere GraalVM)
gradle :hodei-pipelines-cli:nativeCompile

# Usar el binario nativo directamente
./hodei-pipelines-cli/build/native/nativeCompile/hp version

# O crear distribuciÃ³n completa
gradle :hodei-pipelines-cli:createNativeDistributions

# Instalar a nivel del sistema (opcional)
sudo cp hodei-pipelines-cli/build/distributions/native/linux-x64/hp /usr/local/bin/
hp version
```

**Beneficios del binario nativo:**
- âš¡ **Inicio ultra-rÃ¡pido** (sin overhead de JVM)
- ğŸš€ **No requiere Java** (ejecutable independiente)
- ğŸ“¦ **DistribuciÃ³n de archivo Ãºnico** (58MB autocontenido)
- ğŸ”§ **Todas las funciones CLI** (35+ comandos incluidos)

### OpciÃ³n B: DistribuciÃ³n JAR (Tradicional)

Si GraalVM no estÃ¡ disponible:

```bash
# Compilar el CLI
gradle :hodei-pipelines-cli:assemble

# Extraer la distribuciÃ³n
cd hodei-pipelines-cli/build/distributions
tar -xf hodei-pipelines-cli.tar
cd hodei-pipelines-cli/bin

# Hacer ejecutable y aÃ±adir al PATH (opcional)
chmod +x hp
export PATH=$PATH:$(pwd)

# Verificar la instalaciÃ³n
./hp version
```

Salida esperada:
```
ğŸš€ Hodei Pipelines CLI
Version: 1.1.0-SNAPSHOT
Build: $(git rev-parse --short HEAD)

ğŸ–¥ï¸ Server: Not connected
ğŸ’¡ Use 'hp login <url>' to connect to an orchestrator
```

### InstalaciÃ³n de GraalVM (Para Binario Nativo)

Si quieres compilar binarios nativos tÃº mismo:

```bash
# Instalar GraalVM usando SDKMAN (recomendado)
curl -s "https://get.sdkman.io" | bash
source "$HOME/.sdkman/bin/sdkman-init.sh"
sdk install java 21.0.2-graalce
sdk use java 21.0.2-graalce

# Verificar instalaciÃ³n de GraalVM
java -version
native-image --version
```

Salida esperada de GraalVM:
```
openjdk version "21.0.2" 2024-01-16
OpenJDK Runtime Environment GraalVM CE 21.0.2+13.1 (build 21.0.2+13-jvmci-23.1-b30)
```

## Paso 4: Autenticarse en el Orquestador

```bash
# Login con credenciales de admin
hp login http://localhost:8080 --username admin --password admin123

# O login interactivo (solicita credenciales)
hp login http://localhost:8080

# Verificar login
hp whoami
```

Salida esperada:
```
âœ… Login successful!

Username: admin
Orchestrator URL: http://localhost:8080
Context: default
```

## Paso 5: Verificar el Estado del Sistema

```bash
# Verificar salud del orquestador
hp health

# Verificar estado completo del sistema
hp status

# Listar recursos disponibles
hp pool list
hp template list
hp worker list
```

Salida esperada:
```bash
$ hp health
ğŸ¥ Health Check: http://localhost:8080
Overall: healthy
Timestamp: 2024-07-04T10:30:15Z

Components:
  âœ… database: Healthy
  âœ… docker: Connected
  âœ… grpc-server: Running on port 9090

$ hp status
ğŸ“Š System Status
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”— Connected to: http://localhost:8080

âœ… Overall Health: healthy

ğŸŠ Resource Pools: 1
   Active: 1
   Total Capacity: 5 workers

ğŸ“‹ Jobs: 0 total
   ğŸƒ Running: 0
   â³ Queued: 0
   âœ… Completed: 0
   âŒ Failed: 0

ğŸ‘· Workers: 0 total
   ğŸŸ¢ Idle: 0
   ğŸŸ¡ Busy: 0
   ğŸ”´ Offline: 0

$ hp pool list
ğŸŠ Resource Pools:

â€¢ auto-discovered-docker (pool-123)
  Type: docker | Status: active
  Provider: docker
  Created: 2024-07-04T10:30:15Z
```

## Paso 6: Enviar tu Primer Trabajo

### EnvÃ­o BÃ¡sico de Trabajo

```bash
# Enviar un trabajo usando un archivo de pipeline
hp job submit examples/hello-world.pipeline.kts --name "mi-primer-trabajo"

# Enviar con opciones adicionales
hp job submit examples/hello-world.pipeline.kts \
  --name "mi-primer-trabajo" \
  --priority high \
  --pool pool-123 \
  --timeout 300
```

Salida esperada:
```
ğŸ“¤ Submitting job from 'examples/hello-world.pipeline.kts'...

âœ… Job submitted successfully!
   Job ID: job-abc123-def456
   Status: queued
   Queue Position: 1

ğŸ’¡ Track job progress with: hp job status job-abc123-def456
ğŸ’¡ View logs with: hp job logs job-abc123-def456
```

### Validar Antes de Enviar (Dry-run)

```bash
# Probar tu pipeline sin enviarlo realmente
hp job submit examples/hello-world.pipeline.kts --dry-run
```

Salida esperada:
```
ğŸ” Dry-run mode: Validating pipeline...
  Name: hello-world
  Priority: normal
âœ… Pipeline validation successful. Job would be submitted.
```

## Paso 7: Monitorear la EjecuciÃ³n del Trabajo

### Verificar Estado del Trabajo

```bash
# Obtener informaciÃ³n detallada del trabajo
hp job status job-abc123-def456

# Obtener detalles completos del trabajo (estilo kubectl)
hp job describe job-abc123-def456
```

Salida esperada:
```bash
$ hp job status job-abc123-def456
ğŸ“Š Job Status
â•â•â•â•â•â•â•â•â•â•â•â•â•
ID:          job-abc123-def456
Name:        mi-primer-trabajo
Type:        pipeline
Status:      running
Priority:    normal

â±ï¸ Timeline:
  Created:   2024-07-04T10:35:00Z
  Started:   2024-07-04T10:35:05Z

ğŸ”§ Execution:
  Pool:   pool-123
  Worker: worker-789

ğŸ’¡ View logs with: hp job logs job-abc123-def456 --follow
```

### Monitoreo de Logs en Tiempo Real

```bash
# Seguir logs en tiempo real con salida codificada por colores
hp job logs job-abc123-def456 --follow

# Mostrar las Ãºltimas 50 lÃ­neas
hp job logs job-abc123-def456 --tail 50

# Mostrar logs desde un momento especÃ­fico
hp job logs job-abc123-def456 --since 2024-07-04T10:30:00Z
```

Salida esperada de logs:
```
ğŸ“„ Following job logs for: job-abc123-def456
Press Ctrl+C to stop...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[10:35:05] â„¹ï¸ Starting pipeline execution...
[10:35:06] â„¹ï¸ Loading dependencies...
[10:35:08] â„¹ï¸ Executing stage: compile
[10:35:10] â„¹ï¸ Hello from Hodei Pipelines!
[10:35:11] â„¹ï¸ Build Number: 1.0.0
[10:35:12] âœ… Pipeline completed successfully!
```

### Listar y Filtrar Trabajos

```bash
# Listar todos los trabajos
hp job list

# Listar solo trabajos en ejecuciÃ³n
hp job list --status running

# Listar solo trabajos fallidos
hp job list --status failed
```

## Paso 8: GestiÃ³n Avanzada de Recursos

### GestiÃ³n de Pools

```bash
# Crear un nuevo pool de recursos
hp pool create --name mi-docker-pool --type docker --max-workers 10

# Crear con validaciÃ³n dry-run
hp pool create --name test-pool --type kubernetes --dry-run

# Obtener informaciÃ³n detallada del pool
hp pool describe pool-123

# Eliminar un pool (con confirmaciÃ³n)
hp pool delete pool-123

# Forzar eliminaciÃ³n sin confirmaciÃ³n
hp pool delete pool-123 --force
```

### GestiÃ³n de Workers

```bash
# Listar workers con filtrado
hp worker list --pool pool-123 --status idle

# Obtener informaciÃ³n detallada del worker
hp worker describe worker-789

# Verificar estado del worker
hp worker status worker-789
```

### GestiÃ³n de Plantillas

```bash
# Crear una plantilla personalizada
hp template create \
  --name nodejs-template \
  --description "Entorno de desarrollo Node.js 18" \
  --type docker \
  --file nodejs-template.json

# Validar plantilla antes de crear
hp template create \
  --name test-template \
  --description "Plantilla de prueba" \
  --file template.json \
  --dry-run

# Mostrar detalles de plantilla
hp template describe template-123

# Listar plantillas por tipo
hp template list --type docker
```

## Paso 9: Acceso Interactivo (Comandos Shell)

### Acceso Shell a Workers

```bash
# Ejecutar comandos en un worker
hp worker exec worker-789 -- ls -la

# Iniciar un shell interactivo en un worker
hp worker shell worker-789

# Usar un shell especÃ­fico
hp worker shell worker-789 --shell /bin/zsh
```

### Acceso al Contexto del Trabajo

```bash
# Ejecutar comandos en el contexto de un trabajo en ejecuciÃ³n
hp job exec job-abc123-def456 -- cat /logs/output.log

# Iniciar un shell interactivo en el entorno del trabajo
hp job shell job-abc123-def456

# Verificar procesos del trabajo
hp job exec job-abc123-def456 -- ps aux
```

> **Nota**: Los comandos de acceso shell estÃ¡n actualmente en implementaciÃ³n de Fase 1 y requieren soporte de streaming gRPC en el lado del servidor.

## Paso 10: GestiÃ³n del Ciclo de Vida de Trabajos

### Cancelar Trabajos en EjecuciÃ³n

```bash
# Cancelar con prompt de confirmaciÃ³n
hp job cancel job-abc123-def456

# Cancelar con una razÃ³n
hp job cancel job-abc123-def456 --reason "Tiempo de construcciÃ³n excedido"

# Forzar cancelaciÃ³n sin confirmaciÃ³n
hp job cancel job-abc123-def456 --force
```

Salida esperada:
```
âš ï¸  Warning: This will cancel job 'job-abc123-def456' and stop all processing.
Are you sure? Type 'yes' to confirm:
yes

ğŸ›‘ Cancelling job 'job-abc123-def456'...
âœ… Job cancelled successfully!

ğŸ’¡ View final status with: hp job status job-abc123-def456
```

## Paso 11: ConfiguraciÃ³n Multi-Entorno

### Configurar MÃºltiples Contextos

```bash
# AÃ±adir entorno de producciÃ³n
hp login https://prod.hodei.io --username operator --password secret --context prod

# AÃ±adir entorno de staging
hp login https://staging.hodei.io --username dev --password dev123 --context staging

# Listar todos los contextos
hp config get-contexts

# Cambiar entre entornos
hp config use-context prod
hp job submit prod-deploy.kts

hp config use-context staging
hp job submit staging-test.kts

hp config use-context default
hp job submit local-dev.kts
```

### InformaciÃ³n del Contexto Actual

```bash
# Mostrar contexto activo actual
hp config current-context

# Mostrar informaciÃ³n del usuario actual
hp whoami
```

## Monitoreo y DepuraciÃ³n

### Monitoreo de Salud del Sistema

```bash
# VerificaciÃ³n de salud completa
hp health

# Vista general del sistema con mÃ©tricas
hp status

# Verificar salud de recursos especÃ­ficos
hp pool list
hp worker list --status offline
hp job list --status failed
```

### DepuraciÃ³n de Trabajos Fallidos

```bash
# Obtener detalles del trabajo
hp job describe job-failed-123

# Verificar logs del trabajo para errores
hp job logs job-failed-123

# Verificar estado del worker
hp worker describe worker-assigned-to-job

# Verificar capacidad del pool
hp pool describe pool-123
```

### Problemas de ConexiÃ³n del CLI

```bash
# Probar conexiÃ³n
hp health

# Verificar autenticaciÃ³n actual
hp whoami

# Re-autenticarse si es necesario
hp logout
hp login http://localhost:8080

# Cambiar a contexto diferente
hp config get-contexts
hp config use-context <otro-contexto>
```

## Ejemplo de Flujo Completo

```bash
# Terminal 1: Iniciar orquestador
$ gradle :orchestrator:run
ğŸš€ Starting system bootstrap...
âœ… Created user: admin with roles: [ADMIN]
ğŸ—ï¸ Docker environment registered as resource pool
ğŸ“‹ Default worker templates created: 7 templates

# Terminal 2: Usar el CLI HP
$ hp login http://localhost:8080 -u admin -p admin123
âœ… Login successful!

$ hp status
ğŸ“Š System Status
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”— Connected to: http://localhost:8080
âœ… Overall Health: healthy
ğŸŠ Resource Pools: 1
ğŸ‘· Workers: 0 total

$ hp pool list
ğŸŠ Resource Pools:
â€¢ auto-discovered-docker (pool-123)
  Type: docker | Status: active

$ hp job submit examples/hello-world.pipeline.kts --name hello-world
âœ… Job submitted successfully!
   Job ID: job-abc123-def456

$ hp job logs job-abc123-def456 -f
ğŸ“„ Following job logs for: job-abc123-def456
[10:35:10] â„¹ï¸ Hello from Hodei Pipelines!
[10:35:12] âœ… Pipeline completed successfully!

$ hp job list
ğŸ“‹ Jobs:
â€¢ hello-world (job-abc123-def456)
  Status: completed | Type: pipeline
  Created: 2024-07-04T10:35:00Z
```

## Ejemplo Completo: Ejecutar un Job Pesado con Monitoreo

Esta secciÃ³n te guÃ­a paso a paso para ejecutar un job computacionalmente intensivo que genera muchas trazas, desde la configuraciÃ³n hasta el monitoreo completo.

### Paso 1: Crear Template Personalizada (si no existe)

```bash
# Verificar templates existentes
hp template list

# Si no hay templates adecuadas, crear una customizada
cat > heavy-compute-template.json << 'EOF'
{
  "name": "heavy-compute-worker",
  "description": "Template para tareas computacionalmente intensivas",
  "type": "docker",
  "config": {
    "image": "openjdk:17-jdk-slim",
    "cpus": 2.0,
    "memory": "4GB",
    "environment": {
      "JAVA_OPTS": "-Xmx3g -XX:+UseParallelGC"
    },
    "volumes": [
      "/tmp:/workspace"
    ]
  },
  "capabilities": ["compute-intensive", "java-17"],
  "resourceRequirements": {
    "minCpu": 2,
    "minMemory": "4GB",
    "storage": "10GB"
  }
}
EOF

# Crear la template
hp template create \
  --name heavy-compute-worker \
  --description "Template para computaciÃ³n pesada" \
  --type docker \
  --file heavy-compute-template.json

# Verificar que se creÃ³ correctamente
hp template describe heavy-compute-worker
```

### Paso 2: Crear Pool de Recursos Dedicado

```bash
# Crear pool especÃ­fico para trabajos pesados
hp pool create \
  --name heavy-compute-pool \
  --type docker \
  --max-workers 3 \
  --provider docker

# Verificar estado del pool
hp pool describe heavy-compute-pool
```

### Paso 3: Crear Pipeline Computacionalmente Intensivo

Crear archivo `heavy-pipeline.kts` con tareas que generan muchas trazas:

```kotlin
pipeline {
    metadata {
        name = "heavy-computation-pipeline"
        description = "Pipeline computacionalmente intensivo para demostraciÃ³n"
        version = "1.0.0"
    }
    
    stage("PreparaciÃ³n") {
        script {
            println("ğŸš€ Iniciando pipeline computacionalmente intensivo...")
            val startTime = System.currentTimeMillis()
            env["START_TIME"] = startTime.toString()
            
            println("ğŸ“Š ConfiguraciÃ³n del entorno:")
            println("  - Memoria disponible: ${Runtime.getRuntime().maxMemory() / 1024 / 1024} MB")
            println("  - Procesadores: ${Runtime.getRuntime().availableProcessors()}")
            println("  - Timestamp inicio: $startTime")
        }
    }
    
    stage("CÃ¡lculos Intensivos") {
        parallel {
            stage("Fibonacci Masivo") {
                script {
                    println("ğŸ”¢ Calculando secuencia Fibonacci hasta 45...")
                    fun fibonacci(n: Int): Long {
                        if (n <= 1) return n.toLong()
                        return fibonacci(n - 1) + fibonacci(n - 2)
                    }
                    
                    for (i in 30..45) {
                        val result = fibonacci(i)
                        println("  Fibonacci($i) = $result")
                        Thread.sleep(500) // Para generar mÃ¡s trazas
                    }
                    println("âœ… Fibonacci completado")
                }
            }
            
            stage("SimulaciÃ³n de Procesamiento") {
                script {
                    println("âš™ï¸ Simulando procesamiento de datos pesado...")
                    val data = mutableListOf<Double>()
                    
                    // Generar datos aleatorios
                    repeat(1000000) { i ->
                        data.add(Math.random() * 1000)
                        if (i % 100000 == 0) {
                            println("  Generados ${i + 1} elementos...")
                        }
                    }
                    
                    // Procesar datos
                    println("ğŸ“ˆ Procesando datos estadÃ­sticos...")
                    val sum = data.sum()
                    val avg = sum / data.size
                    val max = data.maxOrNull() ?: 0.0
                    val min = data.minOrNull() ?: 0.0
                    
                    println("  ğŸ“Š Resultados estadÃ­sticos:")
                    println("    - Total elementos: ${data.size}")
                    println("    - Suma: $sum")
                    println("    - Promedio: $avg")
                    println("    - MÃ¡ximo: $max")
                    println("    - MÃ­nimo: $min")
                    
                    // SimulaciÃ³n de escritura de archivos
                    println("ğŸ’¾ Simulando escritura de resultados...")
                    repeat(10) { i ->
                        println("  Escribiendo archivo resultado-$i.txt")
                        Thread.sleep(200)
                    }
                    println("âœ… Procesamiento de datos completado")
                }
            }
        }
    }
    
    stage("Pruebas de EstrÃ©s") {
        script {
            println("ğŸ”¥ Ejecutando pruebas de estrÃ©s del sistema...")
            
            // SimulaciÃ³n de uso intensivo de CPU
            val threads = mutableListOf<Thread>()
            repeat(4) { threadIndex ->
                val thread = Thread {
                    println("  ğŸ§µ Hilo $threadIndex iniciado")
                    val startTime = System.currentTimeMillis()
                    while (System.currentTimeMillis() - startTime < 10000) { // 10 segundos
                        // OperaciÃ³n intensiva de CPU
                        var result = 0L
                        for (i in 1..100000) {
                            result += i * i
                        }
                        if ((System.currentTimeMillis() - startTime) % 1000 < 50) {
                            println("    Hilo $threadIndex - Progreso: ${(System.currentTimeMillis() - startTime) / 1000}s")
                        }
                    }
                    println("  âœ… Hilo $threadIndex completado")
                }
                threads.add(thread)
                thread.start()
            }
            
            // Esperar que terminen todos los hilos
            threads.forEach { it.join() }
            println("ğŸ¯ Pruebas de estrÃ©s completadas")
        }
    }
    
    stage("FinalizaciÃ³n") {
        script {
            val endTime = System.currentTimeMillis()
            val startTime = env["START_TIME"]?.toLong() ?: endTime
            val duration = endTime - startTime
            
            println("ğŸ Pipeline completado exitosamente!")
            println("ğŸ“ˆ EstadÃ­sticas de ejecuciÃ³n:")
            println("  - Tiempo total: ${duration / 1000}s")
            println("  - Timestamp fin: $endTime")
            println("  - Memoria utilizada: ${(Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory()) / 1024 / 1024} MB")
            
            // Generar resumen final
            println("ğŸ“‹ Resumen de tareas ejecutadas:")
            println("  âœ… CÃ¡lculos Fibonacci (30-45)")
            println("  âœ… Procesamiento de 1M elementos")
            println("  âœ… Pruebas de estrÃ©s multi-hilo")
            println("  âœ… SimulaciÃ³n de E/O de archivos")
            
            env["EXECUTION_SUMMARY"] = "SUCCESS - Duration: ${duration}ms"
        }
    }
}
```

### Paso 4: Ejecutar el Job y Monitorear en Tiempo Real

```bash
# Enviar el job con configuraciÃ³n especÃ­fica
hp job submit heavy-pipeline.kts \
  --name "heavy-computation-demo" \
  --priority high \
  --pool heavy-compute-pool \
  --timeout 600

# El comando anterior devolverÃ¡ algo como:
# âœ… Job submitted successfully!
# Job ID: job-heavy-abc123-def456
# Status: queued

# Capturar el Job ID para el monitoreo
JOB_ID="job-heavy-abc123-def456"  # Reemplaza con el ID real

# Monitorear estado en tiempo real
echo "ğŸ” Monitoreando job: $JOB_ID"
hp job status $JOB_ID

# Seguir logs en tiempo real (en una terminal separada)
hp job logs $JOB_ID --follow
```

### Paso 5: Monitoreo Avanzado (Terminal separada)

```bash
# Terminal 2: Monitoreo continuo del estado del job
while true; do
    clear
    echo "ğŸ“Š Estado del Job: $JOB_ID"
    echo "=================================="
    hp job status $JOB_ID
    echo ""
    echo "ğŸŠ Estado del Pool:"
    hp pool describe heavy-compute-pool
    echo ""
    echo "ğŸ‘· Workers activos:"
    hp worker list --pool heavy-compute-pool
    echo ""
    echo "ğŸ• $(date) - Actualizando en 5s..."
    sleep 5
done
```

### Paso 6: AnÃ¡lisis Post-EjecuciÃ³n

```bash
# Una vez que el job termine, obtener informaciÃ³n detallada
hp job describe $JOB_ID

# Obtener logs completos para anÃ¡lisis
hp job logs $JOB_ID > heavy-job-logs.txt

# Verificar mÃ©tricas del worker que ejecutÃ³ el job
WORKER_ID=$(hp job describe $JOB_ID | grep "Worker:" | awk '{print $2}')
hp worker describe $WORKER_ID

# Limpiar recursos si es necesario
hp job list --status completed
```

### Salida Esperada del Monitoreo

Durante la ejecuciÃ³n verÃ¡s trazas como:

```
ğŸ“„ Following job logs for: job-heavy-abc123-def456
Press Ctrl+C to stop...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[13:45:01] ğŸš€ Iniciando pipeline computacionalmente intensivo...
[13:45:01] ğŸ“Š ConfiguraciÃ³n del entorno:
[13:45:01]   - Memoria disponible: 3584 MB
[13:45:01]   - Procesadores: 4
[13:45:02] ğŸ”¢ Calculando secuencia Fibonacci hasta 45...
[13:45:02] âš™ï¸ Simulando procesamiento de datos pesado...
[13:45:03]   Fibonacci(30) = 832040
[13:45:03]   Generados 100001 elementos...
[13:45:04]   Fibonacci(31) = 1346269
[13:45:05]   Generados 200001 elementos...
[13:45:06]   Fibonacci(32) = 2178309
[13:45:07]   ğŸ“ˆ Procesando datos estadÃ­sticos...
[13:45:08]   ğŸ“Š Resultados estadÃ­sticos:
[13:45:08]     - Total elementos: 1000000
[13:45:08]     - Suma: 499847293.45
[13:45:09] ğŸ”¥ Ejecutando pruebas de estrÃ©s del sistema...
[13:45:09]   ğŸ§µ Hilo 0 iniciado
[13:45:09]   ğŸ§µ Hilo 1 iniciado
[13:45:10]     Hilo 0 - Progreso: 1s
[13:45:11]     Hilo 1 - Progreso: 2s
[13:45:19]   âœ… Hilo 0 completado
[13:45:20] ğŸ Pipeline completado exitosamente!
[13:45:20] ğŸ“ˆ EstadÃ­sticas de ejecuciÃ³n:
[13:45:20]   - Tiempo total: 19s
[13:45:20]   âœ… CÃ¡lculos Fibonacci (30-45)
```

Este ejemplo te permite ver:
- **CreaciÃ³n de recursos** (templates y pools)
- **EjecuciÃ³n de job pesado** con mÃºltiples stages paralelos
- **Monitoreo en tiempo real** con logs detallados
- **AnÃ¡lisis post-ejecuciÃ³n** de mÃ©tricas y resultados

## Casos de Uso Avanzados

### Pipeline Personalizado con ParÃ¡metros

Crear un archivo de pipeline parametrizado `deploy.pipeline.kts`:
```kotlin
pipeline {
    stage("Deploy") {
        script {
            val env = env("TARGET_ENV") ?: "development"
            val version = env("VERSION") ?: "latest"
            
            println("Deploying version $version to $env environment")
            sh("docker deploy --env $env --version $version")
        }
    }
}
```

Enviar con parÃ¡metros:
```bash
# Enviar con variables de entorno
hp job submit deploy.pipeline.kts \
  --name "deploy-v1.2.3" \
  --priority high \
  --timeout 600
```

### GestiÃ³n de Trabajos en Lote

```bash
# Enviar mÃºltiples trabajos
for i in {1..5}; do
  hp job submit test-job.kts --name "test-job-$i"
done

# Monitorear todos los trabajos
hp job list --status running

# Cancelar todos los trabajos en ejecuciÃ³n (si es necesario)
hp job list --status running | grep job- | awk '{print $2}' | xargs -I {} hp job cancel {} --force
```

### Escalado de Pool de Recursos

```bash
# Crear pool de alto rendimiento
hp pool create \
  --name performance-pool \
  --type docker \
  --max-workers 20 \
  --provider docker

# Enviar trabajos a pool especÃ­fico
hp job submit heavy-computation.kts \
  --name "heavy-task" \
  --pool performance-pool \
  --priority high
```

## SoluciÃ³n de Problemas

### Problemas Comunes y Soluciones

#### Problemas de ConexiÃ³n del CLI
```bash
# Verificar estado del orquestador
curl http://localhost:8080/v1/health

# Verificar instalaciÃ³n del CLI
hp version

# Re-autenticarse
hp logout && hp login http://localhost:8080
```

#### Problemas de EjecuciÃ³n de Trabajos
```bash
# Verificar recursos del sistema
hp status

# Verificar disponibilidad del pool
hp pool list

# Verificar estado de workers
hp worker list

# Revisar detalles del trabajo
hp job describe <job-id>
hp job logs <job-id>
```

#### Problemas de IntegraciÃ³n con Docker
```bash
# Verificar que Docker estÃ© ejecutÃ¡ndose
docker version
docker ps

# Verificar permisos de Docker (Linux)
sudo usermod -aG docker $USER
# (cerrar sesiÃ³n y volver a iniciar)

# Probar conectividad de Docker
docker run hello-world
```

### Obtener Ayuda

```bash
# Ayuda del CLI
hp --help
hp job --help
hp pool create --help

# Verificar versiÃ³n del CLI
hp version

# Vista general del estado del sistema
hp status
```

## PrÃ³ximos Pasos

1. **Explorar Funciones Avanzadas**: Prueba los comandos describe, acceso shell y modos dry-run
2. **Crear Pipelines Personalizados**: Desarrolla pipelines especÃ­ficos para tu flujo de trabajo
3. **Configurar Multi-Entorno**: Configura contextos de staging y producciÃ³n
4. **Integrar con CI/CD**: Usa la API REST para despliegues automatizados
5. **Escalar tu ConfiguraciÃ³n**: Crea mÃºltiples pools y plantillas para diferentes cargas de trabajo

## Referencias

- [Referencia Completa del CLI](./CLI_REFERENCE_HP.md) - DocumentaciÃ³n completa de comandos
- [Roadmap del CLI](./CLI_ROADMAP.md) - ComparaciÃ³n de funciones y roadmap
- [GuÃ­a del Pipeline DSL](./PIPELINE_DSL.md) - GuÃ­a de desarrollo de pipelines
- [Vista General de Arquitectura](./ARCHITECTURE.md) - Detalles de arquitectura del sistema

---

**ğŸ‰ Â¡Felicitaciones!** Ahora tienes una configuraciÃ³n completamente funcional de Hodei Pipelines con capacidades CLI de nivel empresarial. El CLI `hp` proporciona mÃ¡s de 35 comandos para la gestiÃ³n completa de orquestaciÃ³n de pipelines.